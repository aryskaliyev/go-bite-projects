## Chapter 5. Concurrency at Scale
### Error Propagation: Philosophy of Error Propagation
- What errors are? When do they occur, and what benefit do they provide?
	- Errors indicate that your system has entered a state in which it cannot fulfill an operation that a user either explicitly or implicitly requested. Because of this, it needs to relay a few pieces of critical information:
		- **What happened**
			- This is the part of the error that contains information about what happened, e.g., "disk full", "socket closed", or "credentials expired".
		- **When and where it occurred**
			- Errors should always contain a complete stack trace starting with how the call was initiated and ending with where the error was instantiated. The stack trace should *not* be contained in the error message, but should be easily accessible when handling the error up the stack.
			- The error should contain information regarding the context it's running within.
			- The error should contain the time on the machine the error was instantiated on, in UTC.
		- **A friendly user-facing message**
			- The message that gets displayed to the user should be customized to suit your system and its users. It should only contain abbreviated and relevant information from the previous two points. A friendly message is human-centric, gives some indication of whether the issue is transitory, and should be about one line of text.
		- **How the user can get more information**
			- At some point, someone will likely want to know, in detail, what happened when the error occurred. Errors that are presented to users should provide an ID that can be cross-referenced to a corresponding log that displays the full information of the error: time the error occurred (not the time the error was logged), the stack strace -- everything you stuffed into the error when it was created. It can also be helpful to include a hash of the stack trace to aid in aggregating like issues in bug trackers. 

- All errors can be placed in one of two categories:
	- Bugs
	- Known edge cases (e.g., broken network connections, failed disk writes, etc.)

- Bugs are errors that you have not customized to your system, or "raw" errors -- your known edge cases. Raw errors are always bugs. Any error that escapes *our* module without out module's error type can be considered malformed, and a bug. Note that it is only necessary to wrap errors in this fashion at your *own* module boundaries -- public functions/methods -- or when your code can add valuable context.

- Error correctness becomes an emergent property of our system.

- All errors should be logged with as much information as is available. But when displaying errors to users, this is where the distinction between bugs and known edge cases comes in.

- When malformed errors, or bugs, are propagated up to the user, we should also log the error, but then display a friendly message to the user stating something unexpected has happened.

#### Example: Large system with multiple modules: "CLI Component" -> "Intermediary Component" -> "Low Level Component"

- Let's say an error occurs in the "Low Level Component" and we've crafted a well-formed error there to be passed up the stack. *Within the context of the "Low Level Component", this error might be considered well-formed, but within the context of our system, it may not be.* 

```go
func PostReport(id string) error {
	result, err := lowlevel.DoWork()
	if err != nil {
		if _, ok := err.(lowlevel.Error); ok {
			err = Wrap(err, "cannot post report with id %d", id)
		}
		return err
	}
	// ...
}
```

#### Example: Complete example.
```go
type MyError struct {
	Inner error
	Message string
	StackTrace string
	Misc map[string]interface{}
}

func wrapError(err error, messagef string, msgArgs ...interface{}) MyError {
	return MyError{
		Inner: err,
		Message: fmt.Sprintf(messagef, msgArgs...),
		StackTrace: string(debug.Stack()),
		Misc: make(map[string]interface{}),
	}
}

func (err MyError) Error() string {
	return err.Message
}

//--------------------------------------------------------------------------------

// "lowlevel" module

type LowLevelErr struct {
	error
}

func isGloballyExec(path string) (bool, error) {
	info, err := os.Stat(path)
	if err != nil {
		return false, LowLevelErr{(wrapError(err, err.Error()))}
	}
	return info.Mode().Perm()&0100 == 0100, nil
}

// "intermediate" module

type IntermediateErr struct {
	error
}

func runJob(id string) error {
	const jobBinPath = "/bad/job/binary"
	isExecutable, err := isGloballyExec(jobBinPath)
	if err != nil {
		return IntermediateErr{wrapError(
			err,
			"cannot run job %q: requisite binaries not available",
			id,
		)}
	} else if isExecutable == false {
		return wrapError(
			nil,
			"cannot run job %q: requisite binaries are not executable",
			id,
		)
	}
	return exec.Command(jobBinPath, "--id="+id).Run()
}

//--------------------------------------------------------------------------------

func handleError(key int, err error, message string) {
	log.SetPrefix(fmt.Sprintf("[logID: %v]: ", key))
	log.Printf("%#v", err)
	fmt.Printf("[%v] %v", key, message)
}

func main() {
	log.SetOutput(os.Stdout)
	log.SetFlags(log.Ltime|log.LUTC)

	err := runJob("1")
	if err != nil {
		msg := "There was an unexpected issue; please report this as a bug."
		if _, ok := err.(IntermediateErr); ok {
			msg = err.Error()
		}
		handleError(1, err, msg)
	}
}
```

### Timeouts and Cancellation

- Timeouts are crucial to creating a system with behavior you can understand. Cancellation is one natural response to a timeout.

#### What are the reasons we might want our concurrent processes to support timeouts?
- System Saturation
	- If our system is saturated (i.e., if its ability to process requests is at capacity), we may want requests at the edges of our system to time out rather than take a long time to field them. Guidelines for when to time out:
		- If the request is unlikely to repeated when it is timed out.
		- If you don't have the resources to store the requests (e.g., memory for in-memory queues, disk space for persisted queues).
		- if the need for the request, or the data it's sending , will go stale.

- Stale data
	- Sometimes the data has a window within which it must be processed before more relevant data is available, or the need to process the data has expired. If a concurrent process takes longer to process the data than this window, we would want to time out and cancel the concurrent process. For instance, if our concurrent process is dequeing a request after a long wait, the request or its data might have become obsolete during the queuing process. <br> If this window is known beforehand, it would make sense to pass our concurrent process a *context.Context* created with *context.WithDeadline*, or *context.WithTimeout*. If the window is not known beforehand, we'd want the parent of the concurrent process to be able to cancel the concurrent process when the need for the request is no longer present. *context.WithCancel* is perfect for this purpose.

- Attempting to prevent deadlocks
	- It is not unreasonable, and even recommended, to place timeouts on *all* of your concurrent operations to guarantee your system won't deadlock. The timeout period's purpose is only to prevent deadlock, and so it only needs to be short enough that a deadlocked system will unblock in a reasonable amount of time for your use case. <br> Remember that attempting to a void a deadlock by setting a timeout can potentially transform your problem from a system that deadlocks to a system that livelocks. However, it is preferable to chance a livelock and fix that as time permits, than for a deadlock to occur and have a system recoverable only by restart. <br> The goal should be to converge on a system without deadlocks where the timeouts are never triggered.

#### Causes of cancellation, and how to build a concurrent process to handle cancellation gracefully. Reasons why a concurrent process might be canceled:

- Timeouts
	- A timeout is an implicit cancellation.

- User intervention
	- For a good user experience, it's usually advisable to start long-running processes concurrently and then report status back to the user at a polling interval, or allow the users to query for status as they see fit. When there are user-facing concurrent operations, it is therefore also sometimes necessary to allow the users to cancel the operation they've started. 
- Parent cancellation
	- For that matter, if any kind of parent of a concurrent operation -- human or otherwise -- stops, as a child of that parent, we will be canceled.

- Replicated requests
	- We may wish to send data to multiple concurrent processes in an attempt to get a faster response from one of them. When the first one comes back, we would want to cancel the rest of the processes.

#### When a concurrent process is canceled, what does that mean for the algorithm that was executing, and its downstream consumers? When writing concurrent code that can be terminated at any time, what things do you need to take into account? 































































