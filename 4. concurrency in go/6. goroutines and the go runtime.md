## Chapter 6. Goroutines and the Go Runtime

### Work Stealing

- Go will handle multiplexing goroutines onto OS threads for you. The algorithm it uses to do this is known as a *work stealing* strategy.

- First, let's look at a naive strategy for sharing work across processors, something called *fair scheduling*. In an effort to ensure all processors were equally utilized, we could evenly distribute the load between all available processors. Imagine there are *n* processors and *x* tasks to perform. In the fair scheduling strategy, each processor would get *x/n* tasks.

- Unfortunately, there are problems with this approach. Go models concurrency using a fork-join model. In a fork-join paradigm, tasks are likely dependent on one another, and it turns out naively splitting them among processors will likely cause one of the processors to be underutilized. Not only that, but it can also lead to poor cache locality as tasks that require the same data are scheduled on other processors.

- Let's see whether a FIFO queue can help with basic load-balancing problems: work tasks get scheduled into the queue, and our processors dequeue tasks as they have capacity, or block on joins.<br> It's better than simply dividing the tasks among the processors because it solves the problem with underutilized processors, but we've now introduced a centralized data structure that all the processors must use. The problem is that continually entering and exiting critical sections is extremely costly. Not only that, but our cache locality problems have only been exacerbated: we're now going to load the centralized queue into each processor's cache every time it wants to enqueue or dequeue a task. Still, for coarse-grained operations, this can be a valid approach. However, goroutines usually aren't coarse-grained, so a centralized queue probably isn't a great choice for our work scheduling algorithm.

- The next leap we could make is to decentralize the work queues. We could give each processor its own thread and a double-ended queue, or *deque*. OK, we've solved our problem with a central data structure under high contention, but what about the problems with cache locality and processor utilization? And on that topic, if the work begins on processor one, and all forked tasks are placed on processor one's queue, how does work ever make it to processor two? And don't we have a problem with context switching now that tasks are moving between queues? 

- Let's go through the rules of how a work-stealing algorithm operates with distributed queues. As s refresher, remember that Go follows a fork-join model for concurrency. Forks are when goroutines are started, and join points are when two or more goroutines are synchronized through channels or types in the *sync* package. The work-stealing algorithm follows a few basic rules. Given a thread of execution:
	- 1. At a fork point, add tasks to the tail of the deque associated with the thread.
	- 2. If the thread is idle, steal work from the head of deque associated with some other random thread.
	- 3. At a join point that cannot be realized yet (i.e., the goroutine it is synchronized with has not completed yet), pop work off the tail of the thread's own deque.
	- 4. If the thread's deque is empty, either:
		- a. Stall at a join.
		- b. Steal work from the head of a random thread's associated deque.

#### Example: Fibbonacci Sequence



























































